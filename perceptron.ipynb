{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "476153e55000c35de56ef350a9057037a1539011805ea82016ba1946b67534df"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Perceptron\n",
    "In here we will analyse the perceptron approach into classification.\n",
    "For that I have prepared a new class called Perceptron in the file [perceptron.py](./perceptron.py). This class is composed by 2 main methods: fit and predict.\n",
    "\n",
    "The fit method is going to use the defined values of the Perceptron class and iterate through the input matrix of values to be classified, and compare that with the prediction of the entry. By doing that, we can increase or decrease the weights of the perceptron to get closer to the expected output in the prediction.\n",
    "\n",
    "The predict method receives an array of values and outputs the predicted value of the perceptron: 1 or 0.\n",
    "\n",
    "In the example given in class, there was a dataset with 3 artists: Beethoven [1, 1, 1, -1, -1], Homero [1, -1, 1, -1, 1] and Picasso [1, 1, -1, -1, 1]. For each of those there was a 5 entry value and a 4 entry output that could be interpreted as music (1,1,0,0), literature (1,0,1,0) and painting (1,0,0,1).\n",
    "\n",
    "Let's try and see if the perceptron implementation would predict those correctly, first by trying Beethoven:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting perceptron 0\noutputs: [1, 1, 1]\nHere is the synapse array: [0.61537927 0.32083183 0.68026276 0.53713407 0.34891569]\nstarting perceptron 1\noutputs: [1, -1, -1]\nHere is the synapse array: [-0.22638552  0.78783571  0.71767154  0.60090263  0.207248  ]\nstarting perceptron 2\noutputs: [-1, 1, -1]\nHere is the synapse array: [-2.42539619 -4.04569941  1.14317442  4.31847408  1.60078625]\nstarting perceptron 3\noutputs: [-1, -1, 1]\nHere is the synapse array: [-0.21793152  0.46841625 -0.0193148   0.54509768  0.81911081]\n1\n1\n0\n0\n"
     ]
    }
   ],
   "source": [
    "from perceptron import Perceptron\n",
    "from class_exercise import dataset, output\n",
    "perceptrons = []\n",
    "for output_column_index, output_item in enumerate(output[0]):\n",
    "    print(f'starting perceptron {output_column_index}')\n",
    "    perc = Perceptron()\n",
    "    outputs = [out[output_column_index] for out in output]\n",
    "    print(f\"outputs: {outputs}\")\n",
    "    perc.fit(dataset, outputs)\n",
    "    print(f'Here is the synapse array: {perc.synapse_array}')\n",
    "    perceptrons.append(perc)\n",
    "\n",
    "to_predict = [1, 1, 1, -1, -1]\n",
    "for perceptron in perceptrons:\n",
    "    print(perceptron.predict(to_predict))"
   ]
  },
  {
   "source": [
    "As we can see from this output, the creation of the 4 perceptrons and the synapse matrix happened automatically, and properly predicted the output of music for Beethoven.\n",
    "Now that we have proven the potential of this implementation, let's try that with the Iris dataset.\n",
    "\n",
    "The first ask is to use just the two first classes of the iris dataset, then to add the third. Let's try for the first two:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Tolerance 0.1 and learning rate 0.1, we've got 100.0% accuracy, ran 6 epochs\nFor Tolerance 0.1 and learning rate 0.01, we've got 100.0% accuracy, ran 9 epochs\nFor Tolerance 0.01 and learning rate 0.1, we've got 100.0% accuracy, ran 6 epochs\nFor Tolerance 0.01 and learning rate 0.01, we've got 100.0% accuracy, ran 11 epochs\nFor Tolerance 0.001 and learning rate 0.1, we've got 100.0% accuracy, ran 6 epochs\nFor Tolerance 0.001 and learning rate 0.01, we've got 100.0% accuracy, ran 12 epochs\nFor Tolerance 0.0001 and learning rate 0.1, we've got 100.0% accuracy, ran 17 epochs\n"
     ]
    }
   ],
   "source": [
    "from iris_dataset_2classes import output, dataset\n",
    "tolerances = [\n",
    "    1e-1,\n",
    "    1e-2,\n",
    "    1e-3,\n",
    "    1e-4,\n",
    "]\n",
    "\n",
    "learning_rates = [\n",
    "    1e-1,\n",
    "    1e-2,\n",
    "    1e-3,\n",
    "    1e-4\n",
    "]\n",
    "\n",
    "tolerable_iters = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6\n",
    "]\n",
    "for tolerance in tolerances:\n",
    "    for learning_rate in learning_rates:\n",
    "        perc = Perceptron(tolerance=tolerance, learning_rate=learning_rate)\n",
    "        perc.fit(dataset, output)\n",
    "        #print(perc.synapse_array)\n",
    "        results = []\n",
    "        for row, result in zip(dataset, output):\n",
    "            results.append(perc.predict(row) == result)\n",
    "        success_rate = (len([result for result in results if result == True])/len(results))\n",
    "        if success_rate == 1:\n",
    "            print(f\"For Tolerance {tolerance} and learning rate {learning_rate}, we've got {success_rate*100}% accuracy, ran {perc.epochs_ran} epochs\")\n"
   ]
  },
  {
   "source": [
    "Now that we were able to converge in the two classess of the iris dataset, the last bit of test is to try and classify all three classes.\n",
    "\n",
    "As perceptrons only have two types of outputs, it's necessary to convert the output class as a binary output. Using this logic, the classes are [0,0], [0,1] and [1,0]."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting perceptron 0\noutputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\nHere is the synapse array: [-0.48585451 -0.41360817  0.76885244  0.38511928]\ntook 100 epochs to converge.\nstarting perceptron 1\noutputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nHere is the synapse array: [-0.64000108  0.32904769  0.32520534  0.39420599]\ntook 11 epochs to converge.\nWe've got 66.66666666666666% accuracy\n"
     ]
    }
   ],
   "source": [
    "from iris_dataset import dataset, output\n",
    "\n",
    "perceptrons = []\n",
    "for output_column_index, output_item in enumerate(output[0]):\n",
    "    print(f'starting perceptron {output_column_index}')\n",
    "    perc = Perceptron()\n",
    "    outputs = [out[output_column_index] for out in output]\n",
    "    print(f\"outputs: {outputs}\")\n",
    "    perc.fit(dataset, outputs)\n",
    "    print(f'Here is the synapse array: {perc.synapse_array}')\n",
    "    print(f\"took {perc.epochs_ran} epochs to converge.\")\n",
    "    perceptrons.append(perc)\n",
    "\n",
    "results = []\n",
    "for row, result in zip(dataset, output):\n",
    "    prediction = [perc.predict(row) for perc in perceptrons]\n",
    "    results.append(prediction == result)\n",
    "print(f\"We've got {(len([result for result in results if result == True])/len(results))*100}% accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}