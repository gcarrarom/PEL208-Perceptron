{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "476153e55000c35de56ef350a9057037a1539011805ea82016ba1946b67534df"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Perceptron\n",
    "In here we will analyse the perceptron approach into classification.\n",
    "For that I have prepared a new class called Perceptron in the file [perceptron.py](./perceptron.py). This class is composed by 2 main methods: fit and predict.\n",
    "\n",
    "The fit method is going to use the defined values of the Perceptron class and iterate through the input matrix of values to be classified, and compare that with the prediction of the entry. By doing that, we can increase or decrease the weights of the perceptron to get closer to the expected output in the prediction.\n",
    "\n",
    "The predict method receives an array of values and outputs the predicted value of the perceptron: 1 or 0.\n",
    "\n",
    "In the example given in class, there was a dataset with 3 artists: Beethoven [1, 1, 1, -1, -1], Homero [1, -1, 1, -1, 1] and Picasso [1, 1, -1, -1, 1]. For each of those there was a 5 entry value and a 4 entry output that could be interpreted as music (1,1,0,0), literature (1,0,1,0) and painting (1,0,0,1).\n",
    "\n",
    "Let's try and see if the perceptron implementation would predict those correctly, first by trying Beethoven:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting perceptron 0\noutputs: [1, 1, 1]\nHere is the synapse array: [ 0.002  0.002  0.002 -0.002 -0.002]\nstarting perceptron 1\noutputs: [1, -1, -1]\nHere is the synapse array: [-0.322  0.082  0.078  0.322 -0.482]\nstarting perceptron 2\noutputs: [-1, 1, -1]\nHere is the synapse array: [-0.32 -0.48  0.08  0.32  0.08]\nstarting perceptron 3\noutputs: [-1, -1, 1]\nHere is the synapse array: [-0.32  0.08 -0.48  0.32  0.08]\n1\n0\n0\n0\n"
     ]
    }
   ],
   "source": [
    "from perceptron import Perceptron\n",
    "from class_exercise import dataset, output\n",
    "perceptrons = []\n",
    "for output_column_index, output_item in enumerate(output[0]):\n",
    "    print(f'starting perceptron {output_column_index}')\n",
    "    perc = Perceptron()\n",
    "    outputs = [out[output_column_index] for out in output]\n",
    "    print(f\"outputs: {outputs}\")\n",
    "    perc.fit(dataset, outputs)\n",
    "    print(f'Here is the synapse array: {perc.synapse_array}')\n",
    "    perceptrons.append(perc)\n",
    "\n",
    "to_predict = [1, 1, 1, -1, -1]\n",
    "for perceptron in perceptrons:\n",
    "    print(perceptron.predict(to_predict))"
   ]
  },
  {
   "source": [
    "As we can see from this output, the creation of the 4 perceptrons and the synapse matrix happened automatically, and properly predicted the output of music for Beethoven.\n",
    "Now that we have proven the potential of this implementation, let's try that with the Iris dataset.\n",
    "\n",
    "The first ask is to use just the two first classes of the iris dataset, then to add the third. Let's try for the first two:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.00455493 -0.07995921  0.13228417  0.05222997]\n",
      "For Tolerance 0.1 and learning rate 0.1, we've got 100.0% accuracy\n",
      "[-0.00045549 -0.00799592  0.01322842  0.005223  ]\n",
      "For Tolerance 0.01 and learning rate 0.01, we've got 100.0% accuracy\n",
      "[-4.55492534e-05 -7.99592137e-04  1.32284170e-03  5.22299694e-04]\n",
      "For Tolerance 0.001 and learning rate 0.001, we've got 100.0% accuracy\n",
      "[-4.55492534e-06 -7.99592137e-05  1.32284170e-04  5.22299694e-05]\n",
      "For Tolerance 0.0001 and learning rate 0.0001, we've got 100.0% accuracy\n",
      "[-0.00455493 -0.07995921  0.13228417  0.05222997]\n",
      "For Tolerance 0.0001 and learning rate 0.1, we've got 100.0% accuracy\n",
      "[-0.00045549 -0.00799592  0.01322842  0.005223  ]\n",
      "For Tolerance 0.0001 and learning rate 0.01, we've got 100.0% accuracy\n",
      "[-4.55492534e-05 -7.99592137e-04  1.32284170e-03  5.22299694e-04]\n",
      "For Tolerance 0.0001 and learning rate 0.001, we've got 100.0% accuracy\n",
      "[-4.55492534e-06 -7.99592137e-05  1.32284170e-04  5.22299694e-05]\n",
      "For Tolerance 0.1 and learning rate 0.0001, we've got 100.0% accuracy\n",
      "[-4.55492534e-06 -7.99592137e-05  1.32284170e-04  5.22299694e-05]\n",
      "For Tolerance 0.01 and learning rate 0.0001, we've got 100.0% accuracy\n",
      "[-4.55492534e-06 -7.99592137e-05  1.32284170e-04  5.22299694e-05]\n",
      "For Tolerance 0.001 and learning rate 0.0001, we've got 100.0% accuracy\n"
     ]
    }
   ],
   "source": [
    "from iris_dataset_2classes import output, dataset\n",
    "params = [\n",
    "    (1e-1, 1e-1),\n",
    "    (1e-2, 1e-2),\n",
    "    (1e-3, 1e-3),\n",
    "    (1e-4, 1e-4),\n",
    "    (1e-4, 1e-1),\n",
    "    (1e-4, 1e-2),\n",
    "    (1e-4, 1e-3),\n",
    "    (1e-1, 1e-4),\n",
    "    (1e-2, 1e-4),\n",
    "    (1e-3, 1e-4),\n",
    "]\n",
    "for tolerance, learning_rate in params:\n",
    "    perc = Perceptron(tolerance=tolerance, learning_rate=learning_rate)\n",
    "    perc.fit(dataset, output)\n",
    "    print(perc.synapse_array)\n",
    "    results = []\n",
    "    for row, result in zip(dataset, output):\n",
    "        results.append(perc.predict(row) == result)\n",
    "    print(f\"For Tolerance {tolerance} and learning rate {learning_rate}, we've got {(len([result for result in results if result == True])/len(results))*100}% accuracy\")\n"
   ]
  },
  {
   "source": [
    "Now that we were able to converge in the two classess of the iris dataset, the last bit of test is to try and classify all three classes.\n",
    "\n",
    "As perceptrons only have two types of outputs, it's necessary to convert the output class as a binary output. Using this logic, the classes are [0,0], [0,1] and [1,0]."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting perceptron 0\n",
      "outputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Here is the synapse array: [-0.02892362 -0.02423054  0.040697    0.03245715]\n",
      "starting perceptron 1\n",
      "outputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Here is the synapse array: [ 0.00948405 -0.0142414  -0.00144738 -0.02379526]\n",
      "We've got 66.0% accuracy\n"
     ]
    }
   ],
   "source": [
    "from iris_dataset import dataset, output\n",
    "\n",
    "perceptrons = []\n",
    "for output_column_index, output_item in enumerate(output[0]):\n",
    "    print(f'starting perceptron {output_column_index}')\n",
    "    perc = Perceptron()\n",
    "    outputs = [out[output_column_index] for out in output]\n",
    "    print(f\"outputs: {outputs}\")\n",
    "    perc.fit(dataset, outputs)\n",
    "    print(f'Here is the synapse array: {perc.synapse_array}')\n",
    "    perceptrons.append(perc)\n",
    "\n",
    "results = []\n",
    "for row, result in zip(dataset, output):\n",
    "    prediction = [perc.predict(row) for perc in perceptrons]\n",
    "    results.append(prediction == result)\n",
    "print(f\"We've got {(len([result for result in results if result == True])/len(results))*100}% accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}